{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5417c5",
   "metadata": {
    "papermill": {
     "duration": 0.050514,
     "end_time": "2022-05-17T23:58:11.856072",
     "exception": false,
     "start_time": "2022-05-17T23:58:11.805558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI4Code Pytorch DistilBert Baseline\n",
    "\n",
    "I used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n",
    "and here: https://www.kaggle.com/code/aerdem4/ai4code-pytorch-distilbert-baseline\n",
    "\n",
    "I replaced their model with a DistilBert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347011ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:11.956118Z",
     "iopub.status.busy": "2022-05-17T23:58:11.955719Z",
     "iopub.status.idle": "2022-05-17T23:58:12.045604Z",
     "shell.execute_reply": "2022-05-17T23:58:12.044930Z"
    },
    "papermill": {
     "duration": 0.142592,
     "end_time": "2022-05-17T23:58:12.048092",
     "exception": false,
     "start_time": "2022-05-17T23:58:11.905500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "BERT_PATH = \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\"\n",
    "\n",
    "data_dir = Path('../input/AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313158d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:12.142114Z",
     "iopub.status.busy": "2022-05-17T23:58:12.141888Z",
     "iopub.status.idle": "2022-05-17T23:58:16.492237Z",
     "shell.execute_reply": "2022-05-17T23:58:16.491442Z"
    },
    "papermill": {
     "duration": 4.393436,
     "end_time": "2022-05-17T23:58:16.494087",
     "exception": false,
     "start_time": "2022-05-17T23:58:12.100651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 200/200 [00:01<00:00, 145.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00644e80ec8e70</th>\n",
       "      <th>2d19bafd</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804ac9dd</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3290b2e</th>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40a2cdc4</th>\n",
       "      <td>code</td>\n",
       "      <td>df.info()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28c27206</th>\n",
       "      <td>code</td>\n",
       "      <td>df['zip'].value_counts().head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fd3bbdf3840149</th>\n",
       "      <th>3727a048</th>\n",
       "      <td>markdown</td>\n",
       "      <td>There is 1 csv file in the current version of the dataset:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1400526</th>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's take a quick look at what the data looks like:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916b863e</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb475d5d</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4bebc8b8</th>\n",
       "      <td>markdown</td>\n",
       "      <td>## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type                                                                                                                   source\n",
       "id             cell_id                                                                                                                                    \n",
       "00644e80ec8e70 2d19bafd      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "               804ac9dd      code  import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...\n",
       "               e3290b2e      code                                                              df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()\n",
       "               40a2cdc4      code                                                                                                                df.info()\n",
       "               28c27206      code                                                                                          df['zip'].value_counts().head()\n",
       "...                           ...                                                                                                                      ...\n",
       "fd3bbdf3840149 3727a048  markdown                                                             There is 1 csv file in the current version of the dataset:\\n\n",
       "               f1400526  markdown                                                                     Let's take a quick look at what the data looks like:\n",
       "               916b863e  markdown  ## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...\n",
       "               eb475d5d  markdown  ## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...\n",
       "               4bebc8b8  markdown  ## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...\n",
       "\n",
       "[8735 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TRAIN = 200\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "\n",
    "paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n",
    "notebooks_train = [\n",
    "    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab1dd2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:16.567805Z",
     "iopub.status.busy": "2022-05-17T23:58:16.567605Z",
     "iopub.status.idle": "2022-05-17T23:58:16.584714Z",
     "shell.execute_reply": "2022-05-17T23:58:16.583790Z"
    },
    "papermill": {
     "duration": 0.055919,
     "end_time": "2022-05-17T23:58:16.586619",
     "exception": false,
     "start_time": "2022-05-17T23:58:16.530700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: 051d049a469e47\n",
      "The disordered notebook:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d7e4aeec</th>\n",
       "      <td>code</td>\n",
       "      <td>!pip install pyspark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeb2a838</th>\n",
       "      <td>code</td>\n",
       "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12c1a908</th>\n",
       "      <td>code</td>\n",
       "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7e68995</th>\n",
       "      <td>code</td>\n",
       "      <td>df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320bedc7</th>\n",
       "      <td>code</td>\n",
       "      <td>df1.printSchema()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61a146d1</th>\n",
       "      <td>markdown</td>\n",
       "      <td>This is the in-sample accuracy which is generally higher than the out-sample accuracy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0d7a91e3</th>\n",
       "      <td>markdown</td>\n",
       "      <td>The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0b25242</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b7707e6</th>\n",
       "      <td>markdown</td>\n",
       "      <td>The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503a84f0</th>\n",
       "      <td>markdown</td>\n",
       "      <td>### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "d7e4aeec      code                                                                                                     !pip install pyspark\n",
       "aeb2a838      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
       "12c1a908      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
       "e7e68995      code  df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...\n",
       "320bedc7      code                                                                                                        df1.printSchema()\n",
       "...            ...                                                                                                                      ...\n",
       "61a146d1  markdown                                  This is the in-sample accuracy which is generally higher than the out-sample accuracy. \n",
       "0d7a91e3  markdown  The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...\n",
       "c0b25242  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
       "1b7707e6  markdown  The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...\n",
       "503a84f0  markdown  ### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an example notebook\n",
    "nb_id = df.index.unique('id')[6]\n",
    "print('Notebook:', nb_id)\n",
    "\n",
    "print(\"The disordered notebook:\")\n",
    "nb = df.loc[nb_id, :]\n",
    "display(nb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8c2f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:16.662675Z",
     "iopub.status.busy": "2022-05-17T23:58:16.662481Z",
     "iopub.status.idle": "2022-05-17T23:58:18.818612Z",
     "shell.execute_reply": "2022-05-17T23:58:18.817904Z"
    },
    "papermill": {
     "duration": 2.195838,
     "end_time": "2022-05-17T23:58:18.820571",
     "exception": false,
     "start_time": "2022-05-17T23:58:16.624733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n",
       "00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n",
       "0001bdd4021779    [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310c80, 073e27e5, 015d52a4, ad7679ef, 7fde4f04, 07c52510, 0a1a7a39, 0bcd3...\n",
       "0001daf4c2c76d    [97266564, a898e555, 86605076, 76cc2642, ef279279, df6c939f, 2476da96, 00f87d0a, ae93e8e6, 58aadb1d, d20b0094, 986fd...\n",
       "0002115f48f982                                 [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe576, a3188e54, b3f6e12d, ee7655ca, 84125b7a]\n",
       "                                                                           ...                                                           \n",
       "fffc30d5a0bc46    [09727c0c, ff1ea6a0, ddfef603, a01ce9b3, 3ba953ee, bf92a015, f4a0492a, 095812e6, 53125cfe, aa32a700, 63340e73, 06d8c...\n",
       "fffc3b44869198    [978a5137, faa48f03, 28dfb12a, eea2e812, 64fef97c, 4e0d1510, 58e68f2c, 8784e700, 4bd5a4cf, dc14bfec, 2aff7603, 8047d...\n",
       "fffc63ff750064    [5015c300, 411b85d9, 8238198c, f4781d1d, b5532930, e1f223e5, e7e67119, 4aaf741d, 7229cce6, a7fa3628, e4c2fa86, 1f8f9...\n",
       "fffcd063cda949    [7e6266ad, d8281fc5, d4ffcaef, 3e0e4a47, 21387fc8, cc229f9a, baed9c8b, d1bb21aa, 82979992, 65f95dad, eba4fa9e, c97e2...\n",
       "fffe1d764579d5    [1a63248d, 9c3b96a5, 1398a873, 4e2d4c2d, f71c538e, 8b44a5e8, 385dff7a, b8254ef8, 4d0e433e, debc496c, e15ae953, e4d79...\n",
       "Name: cell_order, Length: 139256, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()  # Split the string representation of cell_ids into a list\n",
    "\n",
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21595e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:18.897538Z",
     "iopub.status.busy": "2022-05-17T23:58:18.897271Z",
     "iopub.status.idle": "2022-05-17T23:58:18.904543Z",
     "shell.execute_reply": "2022-05-17T23:58:18.903813Z"
    },
    "papermill": {
     "duration": 0.047804,
     "end_time": "2022-05-17T23:58:18.906493",
     "exception": false,
     "start_time": "2022-05-17T23:58:18.858689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_orders.loc[\"002ba502bdac45\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb67aabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:18.983376Z",
     "iopub.status.busy": "2022-05-17T23:58:18.983026Z",
     "iopub.status.idle": "2022-05-17T23:58:18.998882Z",
     "shell.execute_reply": "2022-05-17T23:58:18.998016Z"
    },
    "papermill": {
     "duration": 0.056589,
     "end_time": "2022-05-17T23:58:19.000984",
     "exception": false,
     "start_time": "2022-05-17T23:58:18.944395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ordered notebook:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0b25242</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7e4aeec</th>\n",
       "      <td>code</td>\n",
       "      <td>!pip install pyspark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6b2dda</th>\n",
       "      <td>markdown</td>\n",
       "      <td>First, we need to start a SparkSession and create a spark instance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeb2a838</th>\n",
       "      <td>code</td>\n",
       "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12c1a908</th>\n",
       "      <td>code</td>\n",
       "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563f858</th>\n",
       "      <td>code</td>\n",
       "      <td># Inspecting csv file in pandas \\nimport pandas as pd\\npd.read_csv('submission.csv').head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611ae31</th>\n",
       "      <td>markdown</td>\n",
       "      <td>We can also save the model itself for future use so that you don't have to train every time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd0d933d</th>\n",
       "      <td>code</td>\n",
       "      <td>model_final.write().save('titanic_classification.model')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d943cd36</th>\n",
       "      <td>code</td>\n",
       "      <td>! ls titanic_classification.model/*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66c450ba</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Final thought. \\n\\n- We just presented a base model here and established that Spark is basically capable of doing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "c0b25242  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
       "d7e4aeec      code                                                                                                     !pip install pyspark\n",
       "cd6b2dda  markdown                                                      First, we need to start a SparkSession and create a spark instance.\n",
       "aeb2a838      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
       "12c1a908      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
       "...            ...                                                                                                                      ...\n",
       "3563f858      code                              # Inspecting csv file in pandas \\nimport pandas as pd\\npd.read_csv('submission.csv').head()\n",
       "7611ae31  markdown                           We can also save the model itself for future use so that you don't have to train every time.  \n",
       "cd0d933d      code                                                                 model_final.write().save('titanic_classification.model')\n",
       "d943cd36      code                                                                                      ! ls titanic_classification.model/*\n",
       "66c450ba  markdown  # Final thought. \\n\\n- We just presented a base model here and established that Spark is basically capable of doing ...\n",
       "\n",
       "[91 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_order = df_orders.loc[nb_id]\n",
    "\n",
    "print(\"The ordered notebook:\")\n",
    "nb.loc[cell_order, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a301e80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:19.080095Z",
     "iopub.status.busy": "2022-05-17T23:58:19.079870Z",
     "iopub.status.idle": "2022-05-17T23:58:19.092976Z",
     "shell.execute_reply": "2022-05-17T23:58:19.092212Z"
    },
    "papermill": {
     "duration": 0.055112,
     "end_time": "2022-05-17T23:58:19.095792",
     "exception": false,
     "start_time": "2022-05-17T23:58:19.040680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d7e4aeec</th>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>!pip install pyspark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeb2a838</th>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12c1a908</th>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7e68995</th>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320bedc7</th>\n",
       "      <td>8</td>\n",
       "      <td>code</td>\n",
       "      <td>df1.printSchema()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61a146d1</th>\n",
       "      <td>80</td>\n",
       "      <td>markdown</td>\n",
       "      <td>This is the in-sample accuracy which is generally higher than the out-sample accuracy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0d7a91e3</th>\n",
       "      <td>37</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0b25242</th>\n",
       "      <td>0</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b7707e6</th>\n",
       "      <td>11</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503a84f0</th>\n",
       "      <td>78</td>\n",
       "      <td>markdown</td>\n",
       "      <td>### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                          \n",
       "d7e4aeec     1      code                                                                                                     !pip install pyspark\n",
       "aeb2a838     3      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()\n",
       "12c1a908     4      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract\n",
       "e7e68995     6      code  df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...\n",
       "320bedc7     8      code                                                                                                        df1.printSchema()\n",
       "...        ...       ...                                                                                                                      ...\n",
       "61a146d1    80  markdown                                  This is the in-sample accuracy which is generally higher than the out-sample accuracy. \n",
       "0d7a91e3    37  markdown  The basic idea for age imputation is to take the title of the people from the name column and impute with the averag...\n",
       "c0b25242     0  markdown  # Introduction \\n\\nSpark is a hot topic on big data analytics. Spark is an analytics engine for big data processing....\n",
       "1b7707e6    11  markdown  The output of the show() might look ugly, especially if there are a large number of columns in the dataframe. At thi...\n",
       "503a84f0    78  markdown  ### Pipeline \\n\\nAt this stage, it is worth introducing pipeline. In machine learning, it is common to run a sequenc...\n",
       "\n",
       "[91 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
    "nb.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6a2c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:19.175532Z",
     "iopub.status.busy": "2022-05-17T23:58:19.175350Z",
     "iopub.status.idle": "2022-05-17T23:58:19.259665Z",
     "shell.execute_reply": "2022-05-17T23:58:19.258823Z"
    },
    "papermill": {
     "duration": 0.126241,
     "end_time": "2022-05-17T23:58:19.261405",
     "exception": false,
     "start_time": "2022-05-17T23:58:19.135164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00644e80ec8e70</th>\n",
       "      <th>2d19bafd</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804ac9dd</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3290b2e</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40a2cdc4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28c27206</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fd3bbdf3840149</th>\n",
       "      <th>3727a048</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1400526</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916b863e</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb475d5d</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4bebc8b8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rank\n",
       "id             cell_id      \n",
       "00644e80ec8e70 2d19bafd    0\n",
       "               804ac9dd    1\n",
       "               e3290b2e    2\n",
       "               40a2cdc4    3\n",
       "               28c27206    5\n",
       "...                      ...\n",
       "fd3bbdf3840149 3727a048    3\n",
       "               f1400526   12\n",
       "               916b863e    0\n",
       "               eb475d5d   16\n",
       "               4bebc8b8    1\n",
       "\n",
       "[8735 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")\n",
    "\n",
    "df_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058613c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:19.343571Z",
     "iopub.status.busy": "2022-05-17T23:58:19.343096Z",
     "iopub.status.idle": "2022-05-17T23:58:19.543396Z",
     "shell.execute_reply": "2022-05-17T23:58:19.542573Z"
    },
    "papermill": {
     "duration": 0.243529,
     "end_time": "2022-05-17T23:58:19.545893",
     "exception": false,
     "start_time": "2022-05-17T23:58:19.302364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001756c60be8</th>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015c83e2717b</th>\n",
       "      <td>aa2da37e</td>\n",
       "      <td>317b65d12af9df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001bdd4021779</th>\n",
       "      <td>a7711fde</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001daf4c2c76d</th>\n",
       "      <td>090152ca</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002115f48f982</th>\n",
       "      <td>272b483a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc30d5a0bc46</th>\n",
       "      <td>6aed207b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc3b44869198</th>\n",
       "      <td>a6aaa8d7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc63ff750064</th>\n",
       "      <td>0a1b5b65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffcd063cda949</th>\n",
       "      <td>d971e960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe1d764579d5</th>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ancestor_id       parent_id\n",
       "id                                        \n",
       "00001756c60be8    945aea18             NaN\n",
       "00015c83e2717b    aa2da37e  317b65d12af9df\n",
       "0001bdd4021779    a7711fde             NaN\n",
       "0001daf4c2c76d    090152ca             NaN\n",
       "0002115f48f982    272b483a             NaN\n",
       "...                    ...             ...\n",
       "fffc30d5a0bc46    6aed207b             NaN\n",
       "fffc3b44869198    a6aaa8d7             NaN\n",
       "fffc63ff750064    0a1b5b65             NaN\n",
       "fffcd063cda949    d971e960             NaN\n",
       "fffe1d764579d5    3c40bfa6             NaN\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "df_ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10bb4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:19.629220Z",
     "iopub.status.busy": "2022-05-17T23:58:19.628977Z",
     "iopub.status.idle": "2022-05-17T23:58:19.694621Z",
     "shell.execute_reply": "2022-05-17T23:58:19.693872Z"
    },
    "papermill": {
     "duration": 0.109308,
     "end_time": "2022-05-17T23:58:19.696408",
     "exception": false,
     "start_time": "2022-05-17T23:58:19.587100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00644e80ec8e70</td>\n",
       "      <td>2d19bafd</td>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>dc83319e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00644e80ec8e70</td>\n",
       "      <td>804ac9dd</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...</td>\n",
       "      <td>1</td>\n",
       "      <td>dc83319e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00644e80ec8e70</td>\n",
       "      <td>e3290b2e</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()</td>\n",
       "      <td>2</td>\n",
       "      <td>dc83319e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00644e80ec8e70</td>\n",
       "      <td>40a2cdc4</td>\n",
       "      <td>code</td>\n",
       "      <td>df.info()</td>\n",
       "      <td>3</td>\n",
       "      <td>dc83319e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00644e80ec8e70</td>\n",
       "      <td>28c27206</td>\n",
       "      <td>code</td>\n",
       "      <td>df['zip'].value_counts().head()</td>\n",
       "      <td>5</td>\n",
       "      <td>dc83319e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>fd3bbdf3840149</td>\n",
       "      <td>3727a048</td>\n",
       "      <td>markdown</td>\n",
       "      <td>There is 1 csv file in the current version of the dataset:\\n</td>\n",
       "      <td>3</td>\n",
       "      <td>a4b2c4d9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>fd3bbdf3840149</td>\n",
       "      <td>f1400526</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's take a quick look at what the data looks like:</td>\n",
       "      <td>12</td>\n",
       "      <td>a4b2c4d9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>fd3bbdf3840149</td>\n",
       "      <td>916b863e</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...</td>\n",
       "      <td>0</td>\n",
       "      <td>a4b2c4d9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8733</th>\n",
       "      <td>fd3bbdf3840149</td>\n",
       "      <td>eb475d5d</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...</td>\n",
       "      <td>16</td>\n",
       "      <td>a4b2c4d9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>fd3bbdf3840149</td>\n",
       "      <td>4bebc8b8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...</td>\n",
       "      <td>1</td>\n",
       "      <td>a4b2c4d9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id   cell_id cell_type                                                                                                                   source rank  \\\n",
       "0     00644e80ec8e70  2d19bafd      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...    0   \n",
       "1     00644e80ec8e70  804ac9dd      code  import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set_style('whit...    1   \n",
       "2     00644e80ec8e70  e3290b2e      code                                                              df = pd.read_csv('../input/montcoalert/911.csv')\\ndf.head()    2   \n",
       "3     00644e80ec8e70  40a2cdc4      code                                                                                                                df.info()    3   \n",
       "4     00644e80ec8e70  28c27206      code                                                                                          df['zip'].value_counts().head()    5   \n",
       "...              ...       ...       ...                                                                                                                      ...  ...   \n",
       "8730  fd3bbdf3840149  3727a048  markdown                                                             There is 1 csv file in the current version of the dataset:\\n    3   \n",
       "8731  fd3bbdf3840149  f1400526  markdown                                                                     Let's take a quick look at what the data looks like:   12   \n",
       "8732  fd3bbdf3840149  916b863e  markdown  ## Introduction\\r\\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demons...    0   \n",
       "8733  fd3bbdf3840149  eb475d5d  markdown  ## Conclusion\\r\\nThis concludes your starter analysis! To go forward from here, click the blue \"Edit Notebook\" butto...   16   \n",
       "8734  fd3bbdf3840149  4bebc8b8  markdown  ## Exploratory Analysis\\r\\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define...    1   \n",
       "\n",
       "     ancestor_id parent_id  \n",
       "0       dc83319e       NaN  \n",
       "1       dc83319e       NaN  \n",
       "2       dc83319e       NaN  \n",
       "3       dc83319e       NaN  \n",
       "4       dc83319e       NaN  \n",
       "...          ...       ...  \n",
       "8730    a4b2c4d9       NaN  \n",
       "8731    a4b2c4d9       NaN  \n",
       "8732    a4b2c4d9       NaN  \n",
       "8733    a4b2c4d9       NaN  \n",
       "8734    a4b2c4d9       NaN  \n",
       "\n",
       "[8735 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c357c942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:19.780129Z",
     "iopub.status.busy": "2022-05-17T23:58:19.779528Z",
     "iopub.status.idle": "2022-05-17T23:58:20.022785Z",
     "shell.execute_reply": "2022-05-17T23:58:20.022109Z"
    },
    "papermill": {
     "duration": 0.287291,
     "end_time": "2022-05-17T23:58:20.024821",
     "exception": false,
     "start_time": "2022-05-17T23:58:19.737530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")\n",
    "\n",
    "df[\"pct_rank\"].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7238e678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:20.110909Z",
     "iopub.status.busy": "2022-05-17T23:58:20.110679Z",
     "iopub.status.idle": "2022-05-17T23:58:20.814641Z",
     "shell.execute_reply": "2022-05-17T23:58:20.813824Z"
    },
    "papermill": {
     "duration": 0.749135,
     "end_time": "2022-05-17T23:58:20.816653",
     "exception": false,
     "start_time": "2022-05-17T23:58:20.067518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "NVALID = 0.1  # size of validation set\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "\n",
    "train_df = df.loc[train_ind].reset_index(drop=True)\n",
    "val_df = df.loc[val_ind].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a12f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:20.904221Z",
     "iopub.status.busy": "2022-05-17T23:58:20.903507Z",
     "iopub.status.idle": "2022-05-17T23:58:20.916764Z",
     "shell.execute_reply": "2022-05-17T23:58:20.916071Z"
    },
    "papermill": {
     "duration": 0.058797,
     "end_time": "2022-05-17T23:58:20.918458",
     "exception": false,
     "start_time": "2022-05-17T23:58:20.859661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>051d049a469e47</td>\n",
       "      <td>d7e4aeec</td>\n",
       "      <td>code</td>\n",
       "      <td>!pip install pyspark</td>\n",
       "      <td>1</td>\n",
       "      <td>6aff1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>051d049a469e47</td>\n",
       "      <td>aeb2a838</td>\n",
       "      <td>code</td>\n",
       "      <td>from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()</td>\n",
       "      <td>3</td>\n",
       "      <td>6aff1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>051d049a469e47</td>\n",
       "      <td>12c1a908</td>\n",
       "      <td>code</td>\n",
       "      <td>from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract</td>\n",
       "      <td>4</td>\n",
       "      <td>6aff1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051d049a469e47</td>\n",
       "      <td>e7e68995</td>\n",
       "      <td>code</td>\n",
       "      <td>df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...</td>\n",
       "      <td>6</td>\n",
       "      <td>6aff1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>051d049a469e47</td>\n",
       "      <td>320bedc7</td>\n",
       "      <td>code</td>\n",
       "      <td>df1.printSchema()</td>\n",
       "      <td>8</td>\n",
       "      <td>6aff1937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source rank ancestor_id  \\\n",
       "0  051d049a469e47  d7e4aeec      code                                                                                                     !pip install pyspark    1    6aff1937   \n",
       "1  051d049a469e47  aeb2a838      code               from pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName('classification').getOrCreate()    3    6aff1937   \n",
       "2  051d049a469e47  12c1a908      code        from itertools import chain\\nfrom pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract    4    6aff1937   \n",
       "3  051d049a469e47  e7e68995      code  df1 = spark.read.csv('../input/titanic/train.csv',\\\\n                     header=True, inferSchema=True)\\ndf2 = spar...    6    6aff1937   \n",
       "4  051d049a469e47  320bedc7      code                                                                                                        df1.printSchema()    8    6aff1937   \n",
       "\n",
       "  parent_id  pct_rank  \n",
       "0       NaN  0.010989  \n",
       "1       NaN  0.032967  \n",
       "2       NaN  0.043956  \n",
       "3       NaN  0.065934  \n",
       "4       NaN  0.087912  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d62437a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.004972Z",
     "iopub.status.busy": "2022-05-17T23:58:21.004768Z",
     "iopub.status.idle": "2022-05-17T23:58:21.011723Z",
     "shell.execute_reply": "2022-05-17T23:58:21.010966Z"
    },
    "papermill": {
     "duration": 0.05212,
     "end_time": "2022-05-17T23:58:21.013551",
     "exception": false,
     "start_time": "2022-05-17T23:58:20.961431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11007f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.110671Z",
     "iopub.status.busy": "2022-05-17T23:58:21.110477Z",
     "iopub.status.idle": "2022-05-17T23:58:21.120415Z",
     "shell.execute_reply": "2022-05-17T23:58:21.119563Z"
    },
    "papermill": {
     "duration": 0.064836,
     "end_time": "2022-05-17T23:58:21.122203",
     "exception": false,
     "start_time": "2022-05-17T23:58:21.057367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30079100123311975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = val_df.groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(df_orders.loc[y_dummy.index], y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531a3213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.209827Z",
     "iopub.status.busy": "2022-05-17T23:58:21.209611Z",
     "iopub.status.idle": "2022-05-17T23:58:21.216589Z",
     "shell.execute_reply": "2022-05-17T23:58:21.215956Z"
    },
    "papermill": {
     "duration": 0.052308,
     "end_time": "2022-05-17T23:58:21.218257",
     "exception": false,
     "start_time": "2022-05-17T23:58:21.165949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code        512\n",
       "markdown    390\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[\"cell_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8cd7590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.306036Z",
     "iopub.status.busy": "2022-05-17T23:58:21.305849Z",
     "iopub.status.idle": "2022-05-17T23:58:21.314398Z",
     "shell.execute_reply": "2022-05-17T23:58:21.313685Z"
    },
    "papermill": {
     "duration": 0.054305,
     "end_time": "2022-05-17T23:58:21.316040",
     "exception": false,
     "start_time": "2022-05-17T23:58:21.261735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n",
    "\n",
    "val_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d38fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.403501Z",
     "iopub.status.busy": "2022-05-17T23:58:21.403315Z",
     "iopub.status.idle": "2022-05-17T23:58:21.410134Z",
     "shell.execute_reply": "2022-05-17T23:58:21.409375Z"
    },
    "papermill": {
     "duration": 0.053452,
     "end_time": "2022-05-17T23:58:21.412373",
     "exception": false,
     "start_time": "2022-05-17T23:58:21.358921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08525798294600553"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(val_df_mark[\"pct_rank\"], np.ones(val_df_mark.shape[0])*train_df_mark[\"pct_rank\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd292739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:21.502370Z",
     "iopub.status.busy": "2022-05-17T23:58:21.501816Z",
     "iopub.status.idle": "2022-05-17T23:58:27.924656Z",
     "shell.execute_reply": "2022-05-17T23:58:27.923861Z"
    },
    "papermill": {
     "duration": 6.469409,
     "end_time": "2022-05-17T23:58:27.926832",
     "exception": false,
     "start_time": "2022-05-17T23:58:21.457423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "# class MarkdownModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MarkdownModel, self).__init__()\n",
    "#         self.distill_bert = DistilBertModel.from_pretrained(BERT_PATH)\n",
    "#         self.top = nn.Linear(768, 1)\n",
    "        \n",
    "#     def forward(self, ids, mask):\n",
    "#         x = self.distill_bert(ids, mask)[0]\n",
    "#         x = self.top(x[:, 0, :])\n",
    "#         x = torch.sigmoid(x)\n",
    "#         return x\n",
    "    \n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.distill_bert = DistilBertModel.from_pretrained(BERT_PATH)\n",
    "\n",
    "        self.top1 = nn.Linear(768, 64)\n",
    "        self.top2 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.2)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0][:, 0, :]\n",
    "        x = self.dropout1(x)\n",
    "        x0 = self.top1(x)\n",
    "        x = self.dropout2(x0)\n",
    "        x = self.top2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e00410d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:28.018392Z",
     "iopub.status.busy": "2022-05-17T23:58:28.018181Z",
     "iopub.status.idle": "2022-05-17T23:58:28.188668Z",
     "shell.execute_reply": "2022-05-17T23:58:28.187958Z"
    },
    "papermill": {
     "duration": 0.218466,
     "end_time": "2022-05-17T23:58:28.190838",
     "exception": false,
     "start_time": "2022-05-17T23:58:27.972372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  3227,  1010,  1996,  3392,  1011,  2241,  7241,  4118, 10438,\n",
       "          2488,  2084,  1996,  7399,  2944,  1998,  2426,  1996,  3392,  1011,\n",
       "          2241,  2944,  1010, 17978, 12992,  2075, 10438,  2488,  2084,  6721,\n",
       "          3224,  1012,  2057,  2089,  3231,  2367,  4118,  2005,  2256,  2345,\n",
       "         12339,  1012,  1001, 17547,  2085,  2057,  3579,  2006,  2437,  1037,\n",
       "         17547,  2006,  3231,  2951,  1998, 12040,  1996,  2765,  1012,  2057,\n",
       "          2342,  2000,  3582,  1996,  6635,  2168,  7709,  2005,  1996,  3231,\n",
       "          2951,  2005,  2951,  9344,  1012,  2034,  2057,  9718,  1996, 20346,\n",
       "          1998,  2156,  2065,  2045,  2024,  2151,  4394,  5300,  1999,  1996,\n",
       "          3231,  2951,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0.7473]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, max_len):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "\n",
    "        return ids, mask, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "train_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN)\n",
    "val_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN)\n",
    "\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee775df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:28.280336Z",
     "iopub.status.busy": "2022-05-17T23:58:28.280106Z",
     "iopub.status.idle": "2022-05-17T23:58:28.286119Z",
     "shell.execute_reply": "2022-05-17T23:58:28.285471Z"
    },
    "papermill": {
     "duration": 0.052935,
     "end_time": "2022-05-17T23:58:28.287907",
     "exception": false,
     "start_time": "2022-05-17T23:58:28.234972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                      051d049a469e47\n",
       "cell_id                                                                                                                       ab896c1d\n",
       "cell_type                                                                                                                     markdown\n",
       "source         Generally, the tree-based ensemble method performs better than the linear model and among the tree-based model, grad...\n",
       "rank                                                                                                                                68\n",
       "ancestor_id                                                                                                                   6aff1937\n",
       "parent_id                                                                                                                          NaN\n",
       "pct_rank                                                                                                                      0.747253\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_mark.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8925ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:28.377372Z",
     "iopub.status.busy": "2022-05-17T23:58:28.377186Z",
     "iopub.status.idle": "2022-05-17T23:58:28.382832Z",
     "shell.execute_reply": "2022-05-17T23:58:28.382185Z"
    },
    "papermill": {
     "duration": 0.052648,
     "end_time": "2022-05-17T23:58:28.384494",
     "exception": false,
     "start_time": "2022-05-17T23:58:28.331846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 2:\n",
    "        lr = 4e-5\n",
    "    elif epoch < 5:\n",
    "        lr = 3e-5\n",
    "    else:\n",
    "        lr = 2e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = lr\n",
    "    return lr\n",
    "    \n",
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n",
    "                                 eps=1e-08)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da2dbda2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:28.474380Z",
     "iopub.status.busy": "2022-05-17T23:58:28.474163Z",
     "iopub.status.idle": "2022-05-17T23:58:28.481997Z",
     "shell.execute_reply": "2022-05-17T23:58:28.480957Z"
    },
    "papermill": {
     "duration": 0.0552,
     "end_time": "2022-05-17T23:58:28.484036",
     "exception": false,
     "start_time": "2022-05-17T23:58:28.428836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "BS = 128\n",
    "NW = 8\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2bf1c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T23:58:28.575832Z",
     "iopub.status.busy": "2022-05-17T23:58:28.575273Z",
     "iopub.status.idle": "2022-05-18T00:00:09.415775Z",
     "shell.execute_reply": "2022-05-18T00:00:09.414968Z"
    },
    "papermill": {
     "duration": 100.888038,
     "end_time": "2022-05-18T00:00:09.417672",
     "exception": false,
     "start_time": "2022-05-17T23:58:28.529634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.2572 lr: 5e-05: 100%|██████████| 20/20 [00:17<00:00,  1.15it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\n",
      "score :  0.5972209690517007\n",
      "Validation MSE: 0.0872\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2275 lr: 4e-05: 100%|██████████| 20/20 [00:15<00:00,  1.26it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.27it/s]\n",
      "score :  0.5894011849980451\n",
      "Validation MSE: 0.0961\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.198 lr: 3e-05: 100%|██████████| 20/20 [00:16<00:00,  1.24it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.97it/s]\n",
      "score :  0.6113567325333094\n",
      "Validation MSE: 0.085\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.17 lr: 3e-05: 100%|██████████| 20/20 [00:15<00:00,  1.26it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.16it/s]\n",
      "score :  0.6090107973172125\n",
      "Validation MSE: 0.092\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.1451 lr: 3e-05: 100%|██████████| 20/20 [00:15<00:00,  1.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.28it/s]\n",
      "score :  0.6325904538482361\n",
      "Validation MSE: 0.0855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    \n",
    "    for e in range(epochs):   \n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        \n",
    "        lr = adjust_lr(optimizer, e)\n",
    "        \n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs[0], inputs[1])\n",
    "\n",
    "            loss = criterion(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "            \n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "            \n",
    "        y_val, y_pred = validate(model, val_loader)\n",
    "            \n",
    "        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "\n",
    "        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "        score = kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n",
    "\n",
    "        print('score : ', score)\n",
    "\n",
    "        output_model_file = f\"./my_own_model_file_{e}_{np.round(score, 5)}.bin\"\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "                        \n",
    "        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n",
    "        print()\n",
    "    return model, y_pred\n",
    "\n",
    "model = MarkdownModel()\n",
    "model = model.cuda()\n",
    "model, y_pred = train(model, train_loader, val_loader, epochs=5)\n",
    "# model.load_state_dict(torch.load('../input/mymodels2022v2/my_own_model_markdown_file_0_0.78085.bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c956fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:09.676547Z",
     "iopub.status.busy": "2022-05-18T00:00:09.676306Z",
     "iopub.status.idle": "2022-05-18T00:00:09.685128Z",
     "shell.execute_reply": "2022-05-18T00:00:09.684490Z"
    },
    "papermill": {
     "duration": 0.137316,
     "end_time": "2022-05-18T00:00:09.686884",
     "exception": false,
     "start_time": "2022-05-18T00:00:09.549568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df43ccde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:09.944507Z",
     "iopub.status.busy": "2022-05-18T00:00:09.944210Z",
     "iopub.status.idle": "2022-05-18T00:00:09.955663Z",
     "shell.execute_reply": "2022-05-18T00:00:09.954860Z"
    },
    "papermill": {
     "duration": 0.140755,
     "end_time": "2022-05-18T00:00:09.957459",
     "exception": false,
     "start_time": "2022-05-18T00:00:09.816704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6325904538482361"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(df_orders.loc[y_dummy.index], y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e375ec9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:10.218080Z",
     "iopub.status.busy": "2022-05-18T00:00:10.217604Z",
     "iopub.status.idle": "2022-05-18T00:00:10.272559Z",
     "shell.execute_reply": "2022-05-18T00:00:10.271432Z"
    },
    "papermill": {
     "duration": 0.185532,
     "end_time": "2022-05-18T00:00:10.275125",
     "exception": false,
     "start_time": "2022-05-18T00:00:10.089593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 114.99it/s]\n"
     ]
    }
   ],
   "source": [
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0626c487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:10.534548Z",
     "iopub.status.busy": "2022-05-18T00:00:10.534326Z",
     "iopub.status.idle": "2022-05-18T00:00:10.544930Z",
     "shell.execute_reply": "2022-05-18T00:00:10.544305Z"
    },
    "papermill": {
     "duration": 0.141004,
     "end_time": "2022-05-18T00:00:10.546616",
     "exception": false,
     "start_time": "2022-05-18T00:00:10.405612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57cc8acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:10.807884Z",
     "iopub.status.busy": "2022-05-18T00:00:10.807671Z",
     "iopub.status.idle": "2022-05-18T00:00:10.857812Z",
     "shell.execute_reply": "2022-05-18T00:00:10.856558Z"
    },
    "papermill": {
     "duration": 0.183992,
     "end_time": "2022-05-18T00:00:10.860769",
     "exception": false,
     "start_time": "2022-05-18T00:00:10.676777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " (tensor([  101,  1001, 25169,  2951,   100,  2292,  1005,  1055,  4094,  1996,\n",
       "           2951,  2061,  7473,  2050,  2064,  2022,  4162,   102,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([0.])))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"pct_rank\"] = 0\n",
    "test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)\n",
    "\n",
    "len(test_ds), test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2b73c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:11.136454Z",
     "iopub.status.busy": "2022-05-18T00:00:11.136203Z",
     "iopub.status.idle": "2022-05-18T00:00:12.664919Z",
     "shell.execute_reply": "2022-05-18T00:00:12.663752Z"
    },
    "papermill": {
     "duration": 1.677403,
     "end_time": "2022-05-18T00:00:12.667641",
     "exception": false,
     "start_time": "2022-05-18T00:00:10.990238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "model = MarkdownModel()\n",
    "model = model.cuda()\n",
    "# model.load_state_dict(torch.load('../input/mymodels2022v3/my_own_model_markdown_file_0_0.78169.bin'))\n",
    "y_test = validate(model, test_loader)[1]\n",
    "\n",
    "# model = MarkdownModel()\n",
    "# model = model.cuda()\n",
    "# model.load_state_dict(torch.load('../input/mymodels2022v3/my_own_model_markdown_file_1_0.74917.bin'))\n",
    "# y_test += validate(model, test_loader)[1]/3\n",
    "\n",
    "# model = MarkdownModel()\n",
    "# model = model.cuda()\n",
    "# model.load_state_dict(torch.load('../input/mymodels2022v3/my_own_model_markdown_file_2_0.75551.bin'))\n",
    "# y_test += validate(model, test_loader)[1]/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49ea7f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:12.930311Z",
     "iopub.status.busy": "2022-05-18T00:00:12.930038Z",
     "iopub.status.idle": "2022-05-18T00:00:12.936461Z",
     "shell.execute_reply": "2022-05-18T00:00:12.935726Z"
    },
    "papermill": {
     "duration": 0.139497,
     "end_time": "2022-05-18T00:00:12.938161",
     "exception": false,
     "start_time": "2022-05-18T00:00:12.798664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8388ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:13.201663Z",
     "iopub.status.busy": "2022-05-18T00:00:13.201464Z",
     "iopub.status.idle": "2022-05-18T00:00:13.216843Z",
     "shell.execute_reply": "2022-05-18T00:00:13.216123Z"
    },
    "papermill": {
     "duration": 0.147861,
     "end_time": "2022-05-18T00:00:13.218586",
     "exception": false,
     "start_time": "2022-05-18T00:00:13.070725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c c6cd22db 1372ae9b 39e937ec e25aa9bd 8cb8d28a ba55e576 f9893819 0a226b6a 90ed07ab 7f388a41 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 fe66203e 7844d5f8 5ce8863c 7f270e34 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f 4907b9ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     ddfd239c c6cd22db 1372ae9b 39e937ec e25aa9bd 8cb8d28a ba55e576 f9893819 0a226b6a 90ed07ab 7f388a41 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                54c7cab3 fe66203e 7844d5f8 5ce8863c 7f270e34 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f 4907b9ef...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b357bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T00:00:13.482677Z",
     "iopub.status.busy": "2022-05-18T00:00:13.482462Z",
     "iopub.status.idle": "2022-05-18T00:00:13.489402Z",
     "shell.execute_reply": "2022-05-18T00:00:13.488630Z"
    },
    "papermill": {
     "duration": 0.139626,
     "end_time": "2022-05-18T00:00:13.491068",
     "exception": false,
     "start_time": "2022-05-18T00:00:13.351442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee522f68",
   "metadata": {
    "papermill": {
     "duration": 0.129594,
     "end_time": "2022-05-18T00:00:13.750332",
     "exception": false,
     "start_time": "2022-05-18T00:00:13.620738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.417723,
   "end_time": "2022-05-18T00:00:16.895494",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-17T23:58:03.477771",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
